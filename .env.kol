# ============================================================================
# KOL BIG DATA ANALYTICS â€” Project-Specific Configuration
# ============================================================================
# This file contains environment variables for KOL-specific services
# (Redpanda/Kafka, Spark, MLflow, Cassandra, Redis, API)
#
# IMPORTANT: This project REUSES infrastructure from SME Pulse project:
#   - MinIO (sme-minio)
#   - PostgreSQL (sme-postgres)
#   - Trino (sme-trino)
#   - Hive Metastore (sme-hive-metastore)
#   - Airflow (sme-airflow-webserver)
#
# Prerequisites:
#   1. SME Pulse project must be running
#   2. Shared network 'sme-network' must exist
#   3. SME Pulse services must be on 'sme-network'
# ============================================================================

# ----------------------------------------------------------------------------
# SME Pulse Infrastructure (Shared Services from other project)
# ----------------------------------------------------------------------------
# IMPORTANT: SME Pulse and KOL Analytics are INDEPENDENT domains.
# They share the SAME infrastructure INSTANCE (PostgreSQL, MinIO, Trino)
# but maintain STRICT LOGICAL SEPARATION via:
#   - Separate MinIO buckets (kol-bronze, kol-silver, kol-gold)
#   - Separate PostgreSQL databases (kol_mlflow, kol_metadata)
#   - Separate Trino schemas (iceberg.kol_*)
#   - Separate MLflow experiment prefixes (KOL_*)
#
# This is a LOCAL DEV environment optimization to avoid duplicate infra.
# In PRODUCTION, each project would run on separate infrastructure.
# ----------------------------------------------------------------------------

# PostgreSQL (from SME Pulse)
POSTGRES_HOST=sme-postgres
POSTGRES_PORT=5432
POSTGRES_USER=sme
POSTGRES_PASSWORD=sme123
POSTGRES_DB=kol_mlflow

# MinIO (from SME Pulse)
# Use localhost when running from host machine (outside Docker)
# Use sme-minio when running from inside Docker containers
MINIO_ENDPOINT=http://localhost:9000
MINIO_CONSOLE_ENDPOINT=http://localhost:9001
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123

# KOL Domain-Specific Bucket and Paths
# Single bucket with folder structure: kol-platform/{bronze,silver,gold,mlflow}
# Separate from SME Pulse bucket (sme-lake/)
MINIO_BUCKET=kol-platform
MINIO_PATH_BRONZE=bronze
MINIO_PATH_SILVER=silver
MINIO_PATH_GOLD=gold
MINIO_PATH_MLFLOW=mlflow

# Trino (from SME Pulse)
TRINO_HOST=sme-trino
TRINO_PORT=8080
TRINO_CATALOG=minio

# KOL Domain-Specific Trino Schemas
# These schemas are separate from SME schemas (iceberg.sme_*)
TRINO_SCHEMA_BRONZE=kol_bronze
TRINO_SCHEMA_SILVER=kol_silver
TRINO_SCHEMA_GOLD=kol_gold

# Hive Metastore (from SME Pulse)
HIVE_METASTORE_URI=thrift://sme-hive-metastore:9083

# Airflow (from SME Pulse - optional)
AIRFLOW_HOST=sme-airflow-webserver
AIRFLOW_PORT=8081

# ----------------------------------------------------------------------------
# Data Ingestion Configuration (Real Data Collection)
# ----------------------------------------------------------------------------
# YouTube Data API v3 (for real trending videos)
# Get FREE API key: https://console.cloud.google.com/apis/credentials
# Quota: 10,000 units/day (~3,000 trending videos)
YOUTUBE_API_KEY=AIzaSyCIHqU02IaYwZirVV8QZzHcaCrUcaXUhz4

# Optional: Additional data source API keys can be added here
# TWITTER_API_KEY=
# INSTAGRAM_API_TOKEN=

# ----------------------------------------------------------------------------
# Redpanda Configuration (Kafka-compatible streaming platform)
# ----------------------------------------------------------------------------
# External ports (accessible from host machine)
KAFKA_EXTERNAL_PORT=19092
KAFKA_PROXY_PORT=18082
SCHEMA_REGISTRY_PORT=18081

# Kafka UI port
KAFKA_UI_PORT=8082

# Kafka topic configuration (used by initialization scripts)
KAFKA_TOPICS=events.social.raw,events.web.raw,events.tx.raw,features.stream,alerts.stream,metrics.windowed
KAFKA_PARTITIONS=6
KAFKA_REPLICAS=1

# ----------------------------------------------------------------------------
# Apache Spark Configuration (unified for streaming + batch)
# ----------------------------------------------------------------------------
SPARK_MASTER_PORT=7077
SPARK_MASTER_UI_PORT=8084
SPARK_HISTORY_PORT=18080
SPARK_WORKER_MEMORY=2G
SPARK_WORKER_CORES=2

# Spark Structured Streaming configuration
SPARK_STREAMING_TRIGGER_INTERVAL=5s  # Micro-batch interval (1s, 5s, 10s)
SPARK_STREAMING_CHECKPOINT_LOCATION=/opt/spark/checkpoints
SPARK_STREAMING_MAX_OFFSETS_PER_TRIGGER=10000

# ----------------------------------------------------------------------------
# Cassandra Configuration (time-series metrics storage)
# ----------------------------------------------------------------------------
CASSANDRA_PORT=9042
CASSANDRA_KEYSPACE=kol_metrics
CASSANDRA_REPLICATION_FACTOR=1

# ----------------------------------------------------------------------------
# Redis Configuration (cache & pub/sub)
# ----------------------------------------------------------------------------
REDIS_PORT=16379  # Changed from 6379 to avoid conflict with SME Redis
REDIS_PASSWORD=
REDIS_MAX_MEMORY=512mb

# ----------------------------------------------------------------------------
# MLflow Configuration (experiment tracking & model registry)
# ----------------------------------------------------------------------------
MLFLOW_PORT=5000

# MLflow experiment and model names
# Use KOL_ prefix to separate from SME experiments (SME_*)
MLFLOW_EXPERIMENT_NAME=KOL_models
MLFLOW_MODEL_NAME_TRUST=KOL_trust_ensemble
MLFLOW_MODEL_NAME_SUCCESS=KOL_success_forecast
MLFLOW_MODEL_STAGE=Production  # None | Staging | Production | Archived

# ----------------------------------------------------------------------------
# Model Training Configuration
# ----------------------------------------------------------------------------
TRAIN_MODE=batch  # batch | online | auto
ENABLE_GPU=false  # Set to true if GPU is available

# Training schedule (for Airflow DAGs)
TRAIN_SCHEDULE_TRUST=0 2 * * *    # Daily at 2 AM
TRAIN_SCHEDULE_SUCCESS=0 3 * * *  # Daily at 3 AM

# ----------------------------------------------------------------------------
# Inference API Configuration
# ----------------------------------------------------------------------------
API_PORT=8000
API_HOST=0.0.0.0
API_WORKERS=4
API_AUTH_TOKEN=dev-token-change-in-production-use-strong-token

# API rate limiting
API_RATE_LIMIT=100/minute

# Model refresh interval (seconds)
MODEL_REFRESH_INTERVAL=300  # 5 minutes

# ----------------------------------------------------------------------------
# Jupyter Notebook Configuration (optional)
# ----------------------------------------------------------------------------
JUPYTER_PORT=8888
JUPYTER_TOKEN=  # Leave empty to disable token auth (not recommended for production)
JUPYTER_PASSWORD=  # Set hashed password or leave empty

# ----------------------------------------------------------------------------
# Monitoring Configuration (Prometheus & Grafana - optional)
# ----------------------------------------------------------------------------
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin123

# ----------------------------------------------------------------------------
# Feature Store Configuration
# ----------------------------------------------------------------------------
# KOL feature store is in kol-platform bucket, separate from SME
FEATURE_STORE_PATH=s3://kol-platform/silver/features
FEATURE_STORE_TABLE=iceberg.kol_silver.features
FEATURE_UPDATE_INTERVAL=300  # 5 minutes

# ----------------------------------------------------------------------------
# Business Rules & Thresholds
# ----------------------------------------------------------------------------
# Trust score thresholds
TRUST_THRESHOLD_LOW=30
TRUST_THRESHOLD_MEDIUM=60
TRUST_THRESHOLD_HIGH=80

# Anomaly detection thresholds
ANOMALY_FOLLOWER_SPIKE_SIGMA=4  # Standard deviations
ANOMALY_SENTIMENT_DROP_HOURS=3
ANOMALY_FORECAST_DROP_PERCENT=30

# Alert configuration
ALERT_CHANNEL=redis  # redis | kafka | webhook
ALERT_WEBHOOK_URL=

# ----------------------------------------------------------------------------
# Data Retention Configuration
# ----------------------------------------------------------------------------
# Raw events retention (days)
RAW_EVENTS_RETENTION_DAYS=30

# Aggregated metrics retention (days)
METRICS_RETENTION_DAYS=365

# Model artifacts retention (versions)
MODEL_VERSIONS_TO_KEEP=10

# ----------------------------------------------------------------------------
# Development & Debug Configuration
# ----------------------------------------------------------------------------
DEBUG=false
LOG_LEVEL=INFO  # DEBUG | INFO | WARNING | ERROR | CRITICAL

# Enable SQL query logging
SQL_ECHO=false

# Enable detailed error traces
SHOW_ERROR_DETAILS=true

