# ============================================================================
# KOL BIG DATA ANALYTICS â€” Project-Specific Configuration
# ============================================================================
# This file contains environment variables for KOL-specific services
# (Redpanda/Kafka, Spark, MLflow, Cassandra, Redis, API)
#
# IMPORTANT: This project REUSES infrastructure from SME Pulse project:
#   - MinIO (sme-minio)
#   - PostgreSQL (sme-postgres)
#   - Trino (sme-trino)
#   - Hive Metastore (sme-hive-metastore)
#   - Airflow (sme-airflow-webserver)
#
# Prerequisites:
#   1. SME Pulse project must be running
#   2. Shared network 'sme-network' must exist
#   3. SME Pulse services must be on 'sme-network'
# ============================================================================

# ----------------------------------------------------------------------------
# SME Pulse Infrastructure (Shared Services from other project)
# ----------------------------------------------------------------------------
# IMPORTANT: SME Pulse and KOL Analytics are INDEPENDENT domains.
# They share the SAME infrastructure INSTANCE (PostgreSQL, MinIO, Trino)
# but maintain STRICT LOGICAL SEPARATION via:
#   - Separate MinIO buckets (kol-bronze, kol-silver, kol-gold)
#   - Separate PostgreSQL databases (kol_mlflow, kol_metadata)
#   - Separate Trino schemas (iceberg.kol_*)
#   - Separate MLflow experiment prefixes (KOL_*)
#
# This is a LOCAL DEV environment optimization to avoid duplicate infra.
# In PRODUCTION, each project would run on separate infrastructure.
# ----------------------------------------------------------------------------

# PostgreSQL (from SME Pulse)
POSTGRES_HOST=sme-postgres
POSTGRES_PORT=5432
POSTGRES_USER=sme
POSTGRES_PASSWORD=sme123
POSTGRES_DB=kol_mlflow

# MinIO (from SME Pulse)
MINIO_ENDPOINT=http://sme-minio:9000
MINIO_CONSOLE_ENDPOINT=http://sme-minio:9001
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123

# KOL Domain-Specific Bucket Namespaces
# These buckets are separate from SME Pulse buckets (sme-bronze, sme-silver, sme-gold)
MINIO_BUCKET_BRONZE=kol-bronze
MINIO_BUCKET_SILVER=kol-silver
MINIO_BUCKET_GOLD=kol-gold
MINIO_BUCKET_MLFLOW=kol-mlflow

# Trino (from SME Pulse)
TRINO_HOST=sme-trino
TRINO_PORT=8080
TRINO_CATALOG=iceberg

# KOL Domain-Specific Trino Schemas
# These schemas are separate from SME schemas (iceberg.sme_*)
TRINO_SCHEMA_BRONZE=kol_bronze
TRINO_SCHEMA_SILVER=kol_silver
TRINO_SCHEMA_GOLD=kol_gold

# Hive Metastore (from SME Pulse)
HIVE_METASTORE_URI=thrift://sme-hive-metastore:9083

# Airflow (from SME Pulse - optional)
AIRFLOW_HOST=sme-airflow-webserver
AIRFLOW_PORT=8081

# ----------------------------------------------------------------------------
# Redpanda Configuration (Kafka-compatible streaming platform)
# ----------------------------------------------------------------------------
# External ports (accessible from host machine)
KAFKA_EXTERNAL_PORT=19092
KAFKA_PROXY_PORT=18082
SCHEMA_REGISTRY_PORT=18081

# Kafka UI port
KAFKA_UI_PORT=8082

# Kafka topic configuration (used by initialization scripts)
KAFKA_TOPICS=events.social.raw,events.web.raw,events.tx.raw,features.stream,alerts.stream,metrics.windowed
KAFKA_PARTITIONS=6
KAFKA_REPLICAS=1

# ----------------------------------------------------------------------------
# Apache Spark Configuration (unified for streaming + batch)
# ----------------------------------------------------------------------------
SPARK_MASTER_PORT=7077
SPARK_MASTER_UI_PORT=8084
SPARK_HISTORY_PORT=18080
SPARK_WORKER_MEMORY=2G
SPARK_WORKER_CORES=2

# Spark Structured Streaming configuration
SPARK_STREAMING_TRIGGER_INTERVAL=5s  # Micro-batch interval (1s, 5s, 10s)
SPARK_STREAMING_CHECKPOINT_LOCATION=/opt/spark/checkpoints
SPARK_STREAMING_MAX_OFFSETS_PER_TRIGGER=10000

# ----------------------------------------------------------------------------
# Cassandra Configuration (time-series metrics storage)
# ----------------------------------------------------------------------------
CASSANDRA_PORT=9042
CASSANDRA_KEYSPACE=kol_metrics
CASSANDRA_REPLICATION_FACTOR=1

# ----------------------------------------------------------------------------
# Redis Configuration (cache & pub/sub)
# ----------------------------------------------------------------------------
REDIS_PORT=16379
REDIS_PASSWORD=
REDIS_MAX_MEMORY=512mb

# ----------------------------------------------------------------------------
# MLflow Configuration (experiment tracking & model registry)
# ----------------------------------------------------------------------------
MLFLOW_PORT=5000

# MLflow experiment and model names
# Use KOL_ prefix to separate from SME experiments (SME_*)
MLFLOW_EXPERIMENT_NAME=KOL_models
MLFLOW_MODEL_NAME_TRUST=KOL_trust_ensemble
MLFLOW_MODEL_NAME_SUCCESS=KOL_success_forecast
MLFLOW_MODEL_STAGE=Production  # None | Staging | Production | Archived

# ----------------------------------------------------------------------------
# Model Training Configuration
# ----------------------------------------------------------------------------
TRAIN_MODE=batch  # batch | online | auto
ENABLE_GPU=false  # Set to true if GPU is available

# Training schedule (for Airflow DAGs)
TRAIN_SCHEDULE_TRUST=0 2 * * *    # Daily at 2 AM
TRAIN_SCHEDULE_SUCCESS=0 3 * * *  # Daily at 3 AM

# ----------------------------------------------------------------------------
# Inference API Configuration
# ----------------------------------------------------------------------------
API_PORT=8000
API_HOST=0.0.0.0
API_WORKERS=4
API_AUTH_TOKEN=dev-token-change-in-production-use-strong-token

# API rate limiting
API_RATE_LIMIT=100/minute

# Model refresh interval (seconds)
MODEL_REFRESH_INTERVAL=300  # 5 minutes

# ----------------------------------------------------------------------------
# Jupyter Notebook Configuration (optional)
# ----------------------------------------------------------------------------
JUPYTER_PORT=8888
JUPYTER_TOKEN=  # Leave empty to disable token auth (not recommended for production)
JUPYTER_PASSWORD=  # Set hashed password or leave empty

# ----------------------------------------------------------------------------
# Monitoring Configuration (Prometheus & Grafana - optional)
# ----------------------------------------------------------------------------
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin123

# ----------------------------------------------------------------------------
# Feature Store Configuration
# ----------------------------------------------------------------------------
# KOL feature store is in kol-silver bucket, separate from SME
FEATURE_STORE_PATH=s3://kol-silver/features
FEATURE_STORE_TABLE=iceberg.kol_silver.features
FEATURE_UPDATE_INTERVAL=300  # 5 minutes

# ----------------------------------------------------------------------------
# Business Rules & Thresholds
# ----------------------------------------------------------------------------
# Trust score thresholds
TRUST_THRESHOLD_LOW=30
TRUST_THRESHOLD_MEDIUM=60
TRUST_THRESHOLD_HIGH=80

# Anomaly detection thresholds
ANOMALY_FOLLOWER_SPIKE_SIGMA=4  # Standard deviations
ANOMALY_SENTIMENT_DROP_HOURS=3
ANOMALY_FORECAST_DROP_PERCENT=30

# Alert configuration
ALERT_CHANNEL=redis  # redis | kafka | webhook
ALERT_WEBHOOK_URL=

# ----------------------------------------------------------------------------
# Data Retention Configuration
# ----------------------------------------------------------------------------
# Raw events retention (days)
RAW_EVENTS_RETENTION_DAYS=30

# Aggregated metrics retention (days)
METRICS_RETENTION_DAYS=365

# Model artifacts retention (versions)
MODEL_VERSIONS_TO_KEEP=10

# ----------------------------------------------------------------------------
# Development & Debug Configuration
# ----------------------------------------------------------------------------
DEBUG=false
LOG_LEVEL=INFO  # DEBUG | INFO | WARNING | ERROR | CRITICAL

# Enable SQL query logging
SQL_ECHO=false

# Enable detailed error traces
SHOW_ERROR_DETAILS=true

