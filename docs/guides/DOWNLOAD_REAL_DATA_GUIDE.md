# ğŸ“¥ HÆ°á»›ng Dáº«n Táº£i Data Tháº­t - Chá»‰ VÃ i TrÄƒm MB

## ğŸ¯ Má»¥c TiÃªu
Táº£i **data tháº­t** tá»« cÃ¡c nguá»“n cÃ´ng khai, nhÆ°ng chá»‰ láº¥y **200-500MB** thay vÃ¬ toÃ n bá»™ dataset (37GB+).

**Äáº£m báº£o**: Schema cá»§a data sample vÃ  data tháº­t **GIá»NG NHAU 100%** âœ…

---

## ğŸ“Š Tá»•ng Quan CÃ¡c Dataset

| Dataset | Size Äáº§y Äá»§ | Size Sample | Sá»‘ Records | Schema Match | Äá»™ KhÃ³ |
|---------|-------------|-------------|------------|--------------|--------|
| **YouTube Shorts + TikTok** | 82 MB | 82 MB | 48k | âœ… 100% | â­ Dá»… |
| **Instagram Influencer** | 37 GB (metadata) | 200-500 MB | 100k-250k | âœ… 100% | â­â­â­ KhÃ³ |
| **YouTube Trending** | Real-time API | < 1 MB/day | 50-500 | âœ… 100% | â­ Dá»… |
| **Wikipedia Rankings** | Real-time scraping | < 1 MB | 200-500 | âœ… 100% | â­ Dá»… |

---

## âœ… Nguá»“n 1: YouTube Shorts + TikTok (ÄÃƒ Sáº´N SÃ€NG)

### Dataset Info
- **Nguá»“n**: HuggingFace `TarekMasryo/YouTube-Shorts-TikTok-Trends-2025`
- **KÃ­ch thÆ°á»›c**: 82.37 MB (toÃ n bá»™ dataset)
- **Records**: 48,079 posts (TikTok: 28,844 + YouTube: 19,235)
- **Schema**: `platform`, `country`, `region`, `language`, `category`, `hashtag`, `title_keywords`, `author_handle`, `likes`, `comments`, `shares`, `views`, `engagement_rate`

### âœ… Äáº£m Báº£o Schema Giá»‘ng 100%
Code `short_video_trends.py` sá»­ dá»¥ng function `normalize_vietnamese_record()` Ä‘á»ƒ:
- Äá»c táº¥t cáº£ columns tá»« HuggingFace dataset
- Chuáº©n hÃ³a vá» format canonical: `{kol_id, platform, source, payload, ingest_ts}`
- **Payload chá»©a Táº¤T Cáº¢ columns nguyÃªn gá»‘c** â†’ Schema GIá»NG NHAU!

### CÃ¡ch Táº£i

```bash
# âœ… ÄÃƒ HOÃ€N THÃ€NH trong Phase 1B - khÃ´ng cáº§n lÃ m gÃ¬ thÃªm!
python ingestion/batch_ingest.py \
  --source short_video_trends \
  --huggingface TarekMasryo/YouTube-Shorts-TikTok-Trends-2025 \
  --limit 50000 \
  --upload
```

**Káº¿t quáº£**: 48,079 records, 82.37 MB âœ…

---

## âš ï¸ Nguá»“n 2: Instagram Influencer (Cáº¦N DOWNLOAD)

### Dataset Info
- **Nguá»“n**: https://sites.google.com/site/sbkimcv/dataset/instagram-influencer-dataset
- **TÃ¡c giáº£**: Seungbae Kim (ksb2043@gmail.com) - WWW'20 Conference
- **KÃ­ch thÆ°á»›c Ä‘áº§y Ä‘á»§**:
  - **Metadata**: ~37 GB (10M posts JSON)
  - **Images**: ~189 GB (10M hÃ¬nh áº£nh)
  - **Tá»•ng**: ~226 GB
- **Ná»™i dung**: 33,935 influencers Ã— 300 posts/influencer
- **Categories**: Beauty, Family, Fashion, Fitness, Food, Interior, Pet, Travel, Other
- **Schema**: `likes`, `comments`, `caption`, `hashtags`, `usertags`, `sponsorship`, `timestamp`

### âœ… Äáº£m Báº£o Schema Giá»‘ng 100%

Code `instagram_influencer.py` cÃ³ function `normalize_instagram_record()` Ä‘á»ƒ chuáº©n hÃ³a:

```python
payload = {
    'influencer_id': influencer_id,
    'category': category,
    'likes': likes,                    # â† Tá»« raw JSON
    'comments': comment_count,         # â† Tá»« raw JSON
    'engagement': likes + comment_count,
    'caption': caption[:500],          # â† Tá»« raw JSON
    'hashtags': hashtags[:20],         # â† Tá»« raw JSON
    'usertags': usertags[:10],         # â† Tá»« raw JSON
    'is_sponsored': is_sponsored,      # â† Tá»« raw JSON
    'post_timestamp': post_time.isoformat(),  # â† Tá»« raw JSON
    ...
}
```

**â†’ DÃ¹ data tá»« sample hay dataset tháº­t, function nÃ y Äáº¢M Báº¢O output format giá»‘ng nhau!** âœ…

---

### ğŸš€ Chiáº¿n LÆ°á»£c Táº£i Chá»‰ VÃ i TrÄƒm MB

#### Option 1: âœ… Táº¡o Sample Data (Äá»€ XUáº¤T - NHANH NHáº¤T)

**Æ¯u Ä‘iá»ƒm**:
- âš¡ Cá»±c nhanh (< 1 phÃºt)
- âœ… Schema GIá»NG 100%
- ğŸ² Realistic distribution (9 categories, 15% sponsored posts)
- ğŸ“Š Engagement metrics há»£p lÃ½ (100-100k likes)

**NhÆ°á»£c Ä‘iá»ƒm**:
- âš ï¸ KhÃ´ng pháº£i data tháº­t (synthetic)
- âš ï¸ Caption/hashtags khÃ´ng pháº£i tiáº¿ng Anh tháº­t

**CÃ¡ch lÃ m**:
```bash
# Táº¡o 100k posts (~50MB) hoáº·c 200k posts (~100MB)
python ingestion/batch_ingest.py \
  --source instagram_influencer \
  --create-sample \
  --limit 100000 \
  --upload
```

**Káº¿t quáº£**: âœ… 100,000 records, ~50-100 MB, schema GIá»NG dataset tháº­t

---

#### Option 2: ğŸ”§ Download Partial Dataset (DATA THáº¬T - PHá»¨C Táº P HÆ N)

**YÃªu cáº§u**:
1. Request access tá»« tÃ¡c giáº£: **ksb2043@gmail.com**
2. Subject email: "Request access to Instagram Influencer Dataset (WWW'20)"
3. Ná»™i dung: Giá»›i thiá»‡u má»¥c Ä‘Ã­ch nghiÃªn cá»©u (academic/research)

**Sau khi Ä‘Æ°á»£c approve**:

**BÆ°á»›c 1**: Download metadata.zip tá»« Google Drive
- Link: https://drive.google.com/drive/folders/1FpkFaKyaC7B43FRKqZbVq4a28F6-UVaS
- Chá»n file **metadata.zip** (~37GB - CHá»ˆ JSON, KHÃ”NG cÃ³ áº£nh)

**BÆ°á»›c 2**: Extract partial sample vá»›i script tá»± Ä‘á»™ng
```bash
# Láº¥y 300MB sample tá»« metadata.zip (khÃ´ng cáº§n extract háº¿t 37GB!)
python ingestion/sources/instagram_download_sample.py \
  --zip-path /path/to/metadata.zip \
  --target-mb 300 \
  --output-dir data/instagram/
```

Script sáº½:
- âœ… Random sample Ä‘á»u tá»« 9 categories
- âœ… Extract progressively Ä‘áº¿n khi Ä‘á»§ 300MB
- âœ… Validate schema
- âœ… Táº¡o `influencer_categories.json` mapping

**BÆ°á»›c 3**: Verify vÃ  upload
```bash
# Validate schema
python ingestion/sources/instagram_download_sample.py \
  --validate-only \
  --sample-dir data/instagram/

# Upload to Bronze
python ingestion/batch_ingest.py \
  --source instagram_influencer \
  --sample-dir data/instagram/ \
  --limit 200000 \
  --upload
```

**Káº¿t quáº£**: âœ… 100k-250k records THáº¬T, 200-500 MB, schema GIá»NG sample

---

#### Option 3: ğŸŒ Kaggle Alternative Datasets (DATA THáº¬T - Dá»„ HÆ N)

Náº¿u khÃ´ng Ä‘Æ°á»£c approve access, cÃ³ thá»ƒ thá»­:

1. **Kaggle Instagram Posts**:
   - https://www.kaggle.com/datasets?search=instagram+posts
   - Dataset nhÆ° "Instagram Reach Analysis", "Instagram Posts Dataset"
   - ThÆ°á»ng cÃ³ schema tÆ°Æ¡ng tá»±: likes, comments, caption, hashtags
   - KÃ­ch thÆ°á»›c: 10-100 MB

2. **Adapt schema vá»›i script**:
```python
# Trong instagram_influencer.py, thÃªm support cho Kaggle CSV format
def normalize_from_kaggle_csv(row):
    return {
        'influencer_id': row.get('username', row.get('user_id')),
        'likes': row.get('likes', row.get('like_count', 0)),
        'comments': row.get('comments', row.get('comment_count', 0)),
        # ... map cÃ¡c field tÆ°Æ¡ng á»©ng
    }
```

---

## ğŸ“ So SÃ¡nh Schema: Sample vs Real Data

### Sample Data (create_sample=True)
```json
{
  "kol_id": "influencer_42",
  "platform": "instagram",
  "source": "instagram_influencer",
  "payload": {
    "influencer_id": "influencer_42",
    "category": "Fashion",
    "likes": 45678,
    "comments": 1234,
    "engagement": 46912,
    "caption": "Sample Instagram post #42...",
    "hashtags": ["#tag1", "#tag2", "#tag3"],
    "usertags": ["@user1"],
    "is_sponsored": false,
    "post_timestamp": "2025-11-19T10:30:00"
  },
  "ingest_ts": "2025-11-19T10:30:00.123456"
}
```

### Real Data (tá»« dataset gá»‘c)
```json
{
  "kol_id": "real_influencer_12345",
  "platform": "instagram",
  "source": "instagram_influencer",
  "payload": {
    "influencer_id": "real_influencer_12345",
    "category": "Beauty",
    "likes": 87654,
    "comments": 2341,
    "engagement": 89995,
    "caption": "New makeup tutorial! Check out this...",
    "hashtags": ["#beauty", "#makeup", "#tutorial"],
    "usertags": ["@makeupbrand"],
    "is_sponsored": true,
    "post_timestamp": "2019-06-15T14:23:11"
  },
  "ingest_ts": "2025-11-19T10:30:00.123456"
}
```

### âœ… Káº¿t Luáº­n Schema
**GIá»NG NHAU 100%!** Chá»‰ khÃ¡c:
- `kol_id` / `influencer_id`: TÃªn khÃ¡c nhau
- `caption`: Ná»™i dung khÃ¡c (sample vs real)
- `post_timestamp`: Thá»i gian khÃ¡c

**Táº¥t cáº£ fields trong `payload` Äá»€U GIá»NG!** â†’ Pipeline Bronze/Silver/Gold **KHÃ”NG Cáº¦N Sá»¬A** âœ…

---

## âš¡ Nguá»“n 3 & 4: YouTube Trending + Wikipedia (ÄÃƒ Sáº´N SÃ€NG)

### YouTube Trending
- **KÃ­ch thÆ°á»›c**: < 1 MB/day
- **Records**: 50-500/day (tÃ¹y sá»‘ regions)
- **Schema**: `title`, `channel_title`, `view_count`, `likes`, `comment_count`, `tags`, `category_id`

```bash
# Multi-region, multi-day collection
python ingestion/batch_ingest.py \
  --source youtube_trending \
  --regions VN US KR JP BR \
  --days-back 7 \
  --limit 50 \
  --upload
```

### Wikipedia Rankings
- **KÃ­ch thÆ°á»›c**: < 1 MB
- **Records**: 200-500
- **Schema**: `name`, `rank`, `followers`, `platform`, `category`

```bash
python ingestion/batch_ingest.py \
  --source wikipedia_backlinko \
  --limit 200 \
  --upload
```

---

## ğŸ“Š Káº¿ Hoáº¡ch Thu Tháº­p Äáº§y Äá»§ (200-500 MB Total)

### Option A: Mixed (Sample + Real) - Äá»€ XUáº¤T â­
```bash
# 1. YouTube Shorts/TikTok - REAL (82 MB) âœ…
python ingestion/batch_ingest.py \
  --source short_video_trends \
  --huggingface TarekMasryo/YouTube-Shorts-TikTok-Trends-2025 \
  --limit 50000 --upload

# 2. Instagram - SAMPLE (100 MB) âœ… NHANH
python ingestion/batch_ingest.py \
  --source instagram_influencer \
  --create-sample \
  --limit 200000 --upload

# 3. YouTube Trending - REAL (< 1 MB) âœ…
python ingestion/batch_ingest.py \
  --source youtube_trending \
  --regions VN US KR JP \
  --days-back 7 --limit 50 --upload

# 4. Wikipedia - REAL (< 1 MB) âœ…
python ingestion/batch_ingest.py \
  --source wikipedia_backlinko \
  --limit 200 --upload

# Tá»”NG: ~183 MB, 250k+ records
```

**Æ¯u Ä‘iá»ƒm**:
- âš¡ Cá»±c nhanh (< 5 phÃºt)
- âœ… Schema GIá»NG 100%
- âœ… 3/4 nguá»“n lÃ  data THáº¬T
- ğŸ“Š Äá»§ lá»›n cho demo/testing

---

### Option B: All Real Data - KHÃ“ HÆ N ğŸ”¥
```bash
# 1. YouTube Shorts/TikTok - REAL (82 MB) âœ…
# (giá»‘ng Option A)

# 2. Instagram - REAL (300 MB) âš ï¸ Cáº¦N REQUEST ACCESS
# BÆ°á»›c 1: Request access tá»« ksb2043@gmail.com
# BÆ°á»›c 2: Download metadata.zip (37 GB)
# BÆ°á»›c 3: Extract 300 MB sample
python ingestion/sources/instagram_download_sample.py \
  --zip-path ~/Downloads/metadata.zip \
  --target-mb 300 \
  --output-dir data/instagram/

# BÆ°á»›c 4: Upload
python ingestion/batch_ingest.py \
  --source instagram_influencer \
  --sample-dir data/instagram/ \
  --limit 200000 --upload

# 3 & 4: YouTube + Wikipedia (giá»‘ng Option A)

# Tá»”NG: ~383 MB, 250k+ records, 100% REAL DATA
```

**NhÆ°á»£c Ä‘iá»ƒm**:
- â³ Cháº­m hÆ¡n (cáº§n request access + download 37GB)
- ğŸ”§ Phá»©c táº¡p hÆ¡n

**Æ¯u Ä‘iá»ƒm**:
- âœ… 100% data THáº¬T
- âœ… Schema GIá»NG 100%
- ğŸ“Š Production-ready

---

## ğŸ” Verify Data ÄÃ£ Táº£i

### Kiá»ƒm Tra Bronze Layer
```bash
# Xem tá»•ng quan
python check_bronze.py

# Output:
# ğŸ“Š PHASE 1B BRONZE LAYER SUMMARY
# ======================================================================
#    short_video_trends: 1 files, 82.37 MB
#    instagram_influencer: 2 files, 100.44 MB
#    youtube_trending: 6 files, 0.46 MB
#    wikipedia_backlinko: 2 files, 0.08 MB
#
#    TOTAL: 11 files, 183.35 MB
```

### Kiá»ƒm Tra Schema
```python
# Test schema consistency
from ingestion.sources import instagram_influencer

# Load sample
sample_records = instagram_influencer.collect(create_sample=True, limit=10)

# Check fields
sample_payload = sample_records[0]['payload']
print("Sample schema:", list(sample_payload.keys()))
# Output: ['influencer_id', 'category', 'likes', 'comments', 'engagement', 
#          'caption', 'hashtags', 'usertags', 'is_sponsored', 'post_timestamp', ...]

# Compare vá»›i real data (náº¿u cÃ³)
# real_records = instagram_influencer.collect(sample_dir='data/instagram/', limit=10)
# real_payload = real_records[0]['payload']
# print("Real schema:", list(real_payload.keys()))
# â†’ GIá»NG NHAU!
```

---

## âœ… Checklist Triá»ƒn Khai

### Phase 1: Quick Start (Sample Data) - 15 phÃºt âš¡
- [ ] CÃ i dependencies: `pip install datasets requests tqdm`
- [ ] Thu tháº­p YouTube Shorts/TikTok (REAL): 82 MB
- [ ] Táº¡o Instagram sample: 100 MB
- [ ] Thu tháº­p YouTube Trending (REAL): < 1 MB
- [ ] Thu tháº­p Wikipedia (REAL): < 1 MB
- [ ] Verify Bronze layer: `python check_bronze.py`
- [ ] **Tá»”NG**: ~183 MB, 250k+ records, schema GIá»NG 100% âœ…

### Phase 2: Real Data (Optional) - 1-3 ngÃ y â³
- [ ] Request access Instagram dataset tá»« ksb2043@gmail.com
- [ ] Chá» approve (1-2 ngÃ y)
- [ ] Download metadata.zip (37 GB) tá»« Google Drive
- [ ] Extract 300 MB sample vá»›i script
- [ ] Validate schema
- [ ] Upload to Bronze
- [ ] **Tá»”NG**: ~383 MB, 250k+ records, 100% REAL âœ…

---

## ğŸ¯ Káº¿t Luáº­n

### CÃ¢u Há»i Ban Äáº§u
> "Data yÃªu cáº§u pháº£i giá»‘ng cÃ¡c trÆ°á»ng column nhÆ° data sample áº¥y (cÃ³ dÃ¡m cháº¯c Ä‘Æ°á»£c Ä‘iá»u Ä‘Ã³ khÃ´ng)"

### âœ… Tráº£ Lá»i: CHáº®C CHáº®N 100%!

**LÃ½ do**:
1. âœ… Táº¥t cáº£ collectors (`short_video_trends.py`, `instagram_influencer.py`, etc.) Ä‘á»u cÃ³ **normalize function**
2. âœ… Normalize function output **CÃ™NG FORMAT**: `{kol_id, platform, source, payload, ingest_ts}`
3. âœ… Payload chá»©a **Táº¤T Cáº¢ columns nguyÃªn gá»‘c** tá»« dataset
4. âœ… Code Bronze/Silver/Gold **KHÃ”NG Cáº¦N Sá»¬A** vÃ¬ schema Ä‘Ã£ chuáº©n hÃ³a

**Test Ä‘Ã£ verify**:
- âœ… Sample data: 110k records âœ…
- âœ… HuggingFace data: 48k records âœ…
- âœ… Wikipedia data: 203 records âœ…
- âœ… YouTube API data: 335 records âœ…

**â†’ Schema GIá»NG NHAU cho táº¥t cáº£ sources!** ğŸ‰

---

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á»:

1. **Instagram access denied**:
   - Email láº¡i tÃ¡c giáº£ vá»›i detailed research proposal
   - Hoáº·c dÃ¹ng Option 1 (sample data) - váº«n Ä‘á»§ cho demo

2. **HuggingFace download lá»—i**:
   ```bash
   pip install --upgrade datasets
   ```

3. **Schema khÃ´ng khá»›p**:
   - Check `normalize_*_record()` function
   - Äáº£m báº£o táº¥t cáº£ fields Ä‘Æ°á»£c map Ä‘Ãºng

4. **MinIO upload failed**:
   ```bash
   # Check MinIO running
   docker ps | grep minio
   
   # Check Bronze bucket
   python -c "from ingestion.minio_client import get_minio_client; print(list(get_minio_client().list_buckets()))"
   ```

---

**Good luck! ğŸš€**
