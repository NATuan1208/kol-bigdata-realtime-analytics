# ğŸ“‹ KOL Analytics Platform - Enterprise E2E Test Plan

> **Document Version**: 1.0.0  
> **Date**: December 12, 2025  
> **Author**: Principal Data Solutions Architect  
> **Status**: ğŸŸ¢ Production Ready

---

## ğŸ“‘ Table of Contents

1. [System Overview](#1-system-overview)
2. [Architectural Audit Report](#2-architectural-audit-report)
3. [Comprehensive E2E Test Plan](#3-comprehensive-e2e-test-plan)
4. [Next Actions](#4-next-actions)

---

## 1. System Overview

### 1.1 Platform Architecture Summary

The **KOL Analytics Platform** implements a **Lambda Architecture** for real-time and batch processing of Key Opinion Leader (KOL) data, designed for influencer marketing intelligence.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        KOL ANALYTICS PLATFORM                                â”‚
â”‚                    (Lambda Architecture - Dec 2025)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   DATA INGESTION  â”‚     â”‚          PROCESSING LAYER                  â”‚   â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  TikTok Scrapers  â”‚â”€â”€â”€â”€â–¶â”‚  â”‚ BATCH (COLD) â”‚  â”‚STREAM (HOT)  â”‚       â”‚   â”‚
â”‚  â”‚  YouTube Scrapers â”‚     â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚       â”‚   â”‚
â”‚  â”‚  Twitter Scrapers â”‚     â”‚  â”‚ Spark Batch   â”‚  â”‚ Spark Stream â”‚       â”‚   â”‚
â”‚  â”‚         â”‚         â”‚     â”‚  â”‚ Bronzeâ†’Silver â”‚  â”‚ Kafkaâ†’Redis  â”‚       â”‚   â”‚
â”‚  â”‚         â–¼         â”‚     â”‚  â”‚ Silverâ†’Gold   â”‚  â”‚              â”‚       â”‚   â”‚
â”‚  â”‚   KAFKA (Redpanda)â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚   5 Topics        â”‚     â”‚         â”‚                  â”‚               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚         â–¼                  â–¼               â”‚   â”‚
â”‚                             â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚                             â”‚  â”‚   MinIO S3   â”‚  â”‚    REDIS     â”‚       â”‚   â”‚
â”‚                             â”‚  â”‚  Data Lake   â”‚  â”‚   Cache      â”‚       â”‚   â”‚
â”‚                             â”‚  â”‚ (Parquet)    â”‚  â”‚ (Real-time)  â”‚       â”‚   â”‚
â”‚                             â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         SERVING LAYER                                â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚   FastAPI       â”‚  â”‚   MLflow        â”‚  â”‚   Streamlit         â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   REST API      â”‚  â”‚   Model         â”‚  â”‚   Dashboard         â”‚  â”‚    â”‚
â”‚  â”‚  â”‚   (35+ endpoints)â”‚  â”‚   Registry      â”‚  â”‚   (3 pages)         â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Technology Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Ingestion** | Python Scrapers, Kafka (Redpanda) | Social media data collection |
| **Batch Processing** | Apache Spark 3.5.1, PySpark | Medallion ETL (Bronzeâ†’Silverâ†’Gold) |
| **Stream Processing** | Spark Structured Streaming | Real-time trending score calculation |
| **Storage** | MinIO (S3), Redis, Parquet | Data lake + real-time cache |
| **ML/AI** | LightGBM, XGBoost, MLflow | Trust/Success score prediction |
| **API** | FastAPI 1.0.0, Pydantic | RESTful API with auto-documentation |
| **Visualization** | Streamlit | Business intelligence dashboard |

### 1.3 Data Flow Summary

| Path | Source | Processing | Sink | Latency |
|------|--------|------------|------|---------|
| **Hot Path** | Kafka Topics | Spark Streaming (30s micro-batch) | Redis | ~30 seconds |
| **Cold Path** | Kafka â†’ MinIO | Spark Batch (Bronzeâ†’Silverâ†’Gold) | MinIO (Parquet) | Batch (hours) |
| **ML Inference** | API Request | LightGBM/XGBoost Models | API Response | ~12ms |

### 1.4 Key Data Assets

| Layer | Tables/Topics | Records | Status |
|-------|---------------|---------|--------|
| **Bronze** (Raw) | 5 Kafka topics | 86,311 | âœ… Complete |
| **Silver** (Cleaned) | 4 tables | 125,266 | âœ… Complete |
| **Gold** (Star Schema) | 8 tables | 161,229 | âœ… Complete |
| **Real-time Stream** | 15 KOLs | 1,755 events | âœ… Live |

---

## 2. Architectural Audit Report

### 2.1 Critical Improvements Needed

Based on Enterprise Best Practices review, the following issues have been identified:

#### ğŸ”´ HIGH PRIORITY (Security & Reliability)

| Issue ID | Category | Description | Location | Recommended Fix |
|----------|----------|-------------|----------|-----------------|
| **SEC-001** | Security | Hardcoded MinIO credentials (`minioadmin/minioadmin`) | `docs/DOMAIN_SEPARATION.md`, `.env.kol` | Use AWS Secrets Manager or HashiCorp Vault for credential management |
| **SEC-002** | Security | Redis running without password authentication | `Config.REDIS_PORT` in streaming code | Enable Redis AUTH with strong password |
| **SEC-003** | Security | API has no authentication (`allow_origins=["*"]`) | `serving/api/main.py` L92-101 | Implement JWT or API key authentication |
| **ERR-001** | Error Handling | Bare `except Exception` without proper logging | `serving/api/routers/predict.py` L467 | Implement structured error handling with error codes |
| **LOG-001** | Logging | Missing structured logging in batch ETL | `batch/etl/*.py` | Implement JSON-structured logging with correlation IDs |

#### ğŸŸ¡ MEDIUM PRIORITY (Scalability & Performance)

| Issue ID | Category | Description | Location | Recommended Fix |
|----------|----------|-------------|----------|-----------------|
| **PERF-001** | Spark Config | Fixed executor cores (2) may not scale | `Config` class in streaming | Use dynamic allocation: `spark.dynamicAllocation.enabled=true` |
| **PERF-002** | Redis | No connection pooling in batch writes | `write_trending_to_redis()` | Implement Redis connection pool |
| **PERF-003** | API | Model loading on first request blocks | `get_model()` function | Implement async model loading at startup |
| **SCALE-001** | Kafka | Single consumer group may bottleneck | Spark Streaming job | Implement consumer group partitioning |

#### ğŸŸ¢ LOW PRIORITY (Maintainability)

| Issue ID | Category | Description | Location | Recommended Fix |
|----------|----------|-------------|----------|-----------------|
| **DOC-001** | Documentation | Missing API versioning strategy | `serving/api/main.py` | Document deprecation policy for /kol endpoints |
| **TEST-001** | Testing | Unit tests have placeholder files only | `tests/unit/test_placeholder.py` | Implement comprehensive unit test suite |
| **CFG-001** | Configuration | Magic numbers in scoring formulas | `TrendingCalculator` class | Extract to configuration file |

### 2.2 Refactoring Recommendations

#### 2.2.1 Security Hardening Plan

```python
# BEFORE (Insecure)
MINIO_ACCESS_KEY = "minioadmin"
MINIO_SECRET_KEY = "minioadmin"

# AFTER (Secure)
import boto3
secrets = boto3.client('secretsmanager')
credentials = secrets.get_secret_value(SecretId='kol-platform/minio')
MINIO_ACCESS_KEY = json.loads(credentials['SecretString'])['access_key']
MINIO_SECRET_KEY = json.loads(credentials['SecretString'])['secret_key']
```

#### 2.2.2 Structured Error Handling

```python
# BEFORE
except Exception as e:
    raise HTTPException(status_code=500, detail=str(e))

# AFTER
from fastapi import status
from pydantic import BaseModel

class ErrorResponse(BaseModel):
    error_code: str
    message: str
    correlation_id: str
    timestamp: str

@app.exception_handler(ModelLoadError)
async def model_error_handler(request: Request, exc: ModelLoadError):
    return JSONResponse(
        status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
        content=ErrorResponse(
            error_code="ML_MODEL_UNAVAILABLE",
            message=str(exc),
            correlation_id=request.state.correlation_id,
            timestamp=datetime.utcnow().isoformat()
        ).dict()
    )
```

#### 2.2.3 Redis Connection Pool

```python
# BEFORE (New connection per batch)
def write_trending_to_redis(batch_df, batch_id):
    r = redis.Redis(host=Config.REDIS_HOST, port=Config.REDIS_PORT)
    # ...

# AFTER (Connection pool)
from redis import ConnectionPool

REDIS_POOL = ConnectionPool(
    host=Config.REDIS_HOST,
    port=Config.REDIS_PORT,
    max_connections=20,
    decode_responses=True
)

def write_trending_to_redis(batch_df, batch_id):
    r = redis.Redis(connection_pool=REDIS_POOL)
    # ...
```

### 2.3 Architecture Strengths

| Aspect | Implementation | Assessment |
|--------|----------------|------------|
| **Lambda Architecture** | Clean separation of Batch (Cold) and Speed (Hot) layers | âœ… Excellent |
| **Medallion Pattern** | Bronze â†’ Silver â†’ Gold data lake structure | âœ… Excellent |
| **ML Model Loading** | Hybrid strategy (MLflow + local fallback) | âœ… Good |
| **API Design** | RESTful with OpenAPI documentation | âœ… Good |
| **Streaming Window** | 5-minute tumbling windows with watermark | âœ… Good |
| **Feature Engineering** | 29 engineered features for Trust Score | âœ… Excellent |

---

## 3. Comprehensive E2E Test Plan

### 3.1 Test Strategy Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         E2E TEST PHASES                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Phase 1: INGESTION           Phase 2: PIPELINE INTEGRITY                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ Scraper JSON format        â€¢ Hot Path: Kafka â†’ Redis                     â”‚
â”‚  â€¢ Kafka topic delivery       â€¢ Cold Path: Bronze â†’ Silver â†’ Gold           â”‚
â”‚  â€¢ Schema validation          â€¢ Data consistency checks                     â”‚
â”‚                                                                              â”‚
â”‚  Phase 3: ML INFERENCE        Phase 4: VISUALIZATION                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  â€¢ Trust Score API            â€¢ Dashboard data accuracy                     â”‚
â”‚  â€¢ Success Score API          â€¢ Real-time refresh                           â”‚
â”‚  â€¢ Trending Score API         â€¢ API response mapping                        â”‚
â”‚  â€¢ Batch prediction           â€¢ Error handling                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3.2 Phase 1: Ingestion Validation

#### 3.2.1 Test Cases

| Test ID | Test Name | Description | Priority |
|---------|-----------|-------------|----------|
| ING-001 | Kafka Topic Existence | Verify all 5 required topics exist | Critical |
| ING-002 | JSON Schema Validation | Verify message format matches expected schema | Critical |
| ING-003 | Message Delivery | Verify messages reach topics within SLA | High |
| ING-004 | Data Import Script | Test `import_json_to_kafka.py --all` | High |
| ING-005 | Consumer Offset | Verify offset management works correctly | Medium |

#### 3.2.2 Test Commands

```bash
# ========================================
# ING-001: Kafka Topic Existence
# ========================================
# Expected: 5 topics (kol.videos.raw, kol.profiles.raw, kol.products.raw, 
#           kol.comments.raw, kol.discovery.raw)

docker exec kol-redpanda rpk topic list

# Acceptance Criteria:
# - All 5 topics listed
# - No error messages

# ========================================
# ING-002: JSON Schema Validation
# ========================================
# Verify message format

docker exec kol-redpanda rpk topic consume kol.videos.raw --num 1 --format json

# Expected schema fields:
# - event_id: string (UUID)
# - event_time: string (ISO 8601)
# - platform: string (tiktok|youtube|twitter)
# - username: string
# - video_id: string
# - video_views: number
# - video_likes: number
# - video_comments: number
# - video_shares: number

# ========================================
# ING-003: Message Delivery
# ========================================
# Test real data import

python scripts/import_json_to_kafka.py --all

# Expected Output:
# âœ… Imported 666 comments to kol.comments.raw
# âœ… Imported 1000 discovery to kol.discovery.raw
# âœ… Imported 8 products to kol.products.raw
# âœ… Imported 28 profiles to kol.profiles.raw
# âœ… Imported 53 videos to kol.videos.raw

# Acceptance Criteria:
# - Total: 1,755 messages imported
# - No timeout errors
# - < 5 seconds per topic

# ========================================
# ING-004: Topic Message Count
# ========================================
docker exec kol-redpanda rpk topic describe kol.videos.raw --print-offsets

# Acceptance Criteria:
# - Offset matches expected message count
# - No partition lag
```

#### 3.2.3 Acceptance Criteria

| Metric | Target | Measurement |
|--------|--------|-------------|
| Topic Creation | 5/5 topics | `rpk topic list` |
| Schema Compliance | 100% | JSON validation |
| Import Success Rate | 100% | Script exit code 0 |
| Import Latency | < 30 seconds total | Timer |

---

### 3.3 Phase 2: Pipeline Integrity

#### 3.3.1 Hot Path Tests (Real-time)

| Test ID | Test Name | Description | Priority |
|---------|-----------|-------------|----------|
| HOT-001 | Streaming Job Start | Verify Spark Streaming job starts successfully | Critical |
| HOT-002 | Kafka Consumption | Verify messages are consumed from topics | Critical |
| HOT-003 | Redis Write | Verify trending scores written to Redis | Critical |
| HOT-004 | Latency SLA | Verify < 60s end-to-end latency | High |
| HOT-005 | Redis Key Schema | Verify correct key naming pattern | High |
| HOT-006 | Score Calculation | Verify trending score formula accuracy | High |

```bash
# ========================================
# HOT-001: Start Streaming Job
# ========================================
docker exec -it kol-spark-master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 \
    /opt/spark-jobs/trending_stream.py

# Acceptance Criteria:
# - "Streaming query started" message appears
# - No exceptions in first 60 seconds
# - Spark UI shows running application

# ========================================
# HOT-002: Verify Kafka Consumption
# ========================================
# Check consumer group lag

docker exec kol-redpanda rpk group describe kol-consumers

# Acceptance Criteria:
# - Consumer group exists
# - Lag < 100 messages after 60 seconds

# ========================================
# HOT-003: Verify Redis Write
# ========================================
# After running streaming for 60 seconds

docker exec kol-redis redis-cli KEYS "trending:*" | wc -l

# Acceptance Criteria:
# - At least 10 keys present
# - Keys follow pattern: trending:{platform}:{kol_id}

# Check specific key content
docker exec kol-redis redis-cli HGETALL "trending:tiktok:meoantrongsuong"

# Expected fields:
# - trending_score (0-100)
# - trending_label (Viral|Hot|Warm|Normal|Cold)
# - velocity
# - momentum
# - updated_at (ISO 8601)

# ========================================
# HOT-004: Verify Ranking Sorted Set
# ========================================
docker exec kol-redis redis-cli ZREVRANGE "ranking:tiktok:trending" 0 9 WITHSCORES

# Acceptance Criteria:
# - Returns up to 10 KOLs
# - Scores in descending order
# - Scores between 0-100

# ========================================
# HOT-005: Latency Measurement
# ========================================
# Time from Kafka publish to Redis read

# Step 1: Get current time
START=$(date +%s)

# Step 2: Publish test message to Kafka
echo '{"event_id":"test-001","platform":"tiktok","username":"test_user","video_views":1000,"video_likes":100}' | \
docker exec -i kol-redpanda rpk topic produce kol.videos.raw

# Step 3: Poll Redis for the key (max 60s)
for i in {1..60}; do
    if docker exec kol-redis redis-cli EXISTS "trending:tiktok:test_user" | grep -q "1"; then
        END=$(date +%s)
        echo "Latency: $((END-START)) seconds"
        break
    fi
    sleep 1
done

# Acceptance Criteria:
# - Latency < 60 seconds (streaming trigger is 30s)
```

#### 3.3.2 Cold Path Tests (Batch)

| Test ID | Test Name | Description | Priority |
|---------|-----------|-------------|----------|
| COLD-001 | Bronze to Silver ETL | Run bronze_to_silver.py successfully | Critical |
| COLD-002 | Silver to Gold ETL | Run silver_to_gold.py successfully | Critical |
| COLD-003 | Data Volume Check | Verify record counts at each layer | High |
| COLD-004 | Schema Validation | Verify output schemas match specification | High |
| COLD-005 | Data Quality | Verify no null primary keys, duplicates | High |
| COLD-006 | MinIO Storage | Verify Parquet files written correctly | Medium |

```bash
# ========================================
# COLD-001: Bronze to Silver ETL
# ========================================
docker exec -it kol-spark-master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
    /opt/batch/etl/bronze_to_silver.py

# Acceptance Criteria:
# - Exit code 0
# - Logs show "Silver layer complete"
# - Processing time < 10 minutes

# ========================================
# COLD-002: Silver to Gold ETL
# ========================================
docker exec -it kol-spark-master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
    /opt/batch/etl/silver_to_gold.py

# Acceptance Criteria:
# - Exit code 0
# - Logs show "Gold layer complete"
# - 8 tables created (4 dimensions + 1 fact + 2 ML + 1 aggregate)

# ========================================
# COLD-003: Data Volume Verification
# ========================================
# Run test_pipeline.py

python tests/test_pipeline.py

# Expected Output:
# TEST SUMMARY
# Bronze Layer (100% Real): âœ… PASS
# Data Schema: âœ… PASS
# Record Samples: âœ… PASS
# Record Count: âœ… PASS

# ========================================
# COLD-004: MinIO Bucket Verification
# ========================================
# Access MinIO Console: http://localhost:9001
# Username: minioadmin | Password: minioadmin

# Verify buckets exist:
# - kol-bronze/
# - kol-silver/
# - kol-gold/

# Or via CLI:
docker exec sme-minio mc ls local/kol-platform/bronze/
docker exec sme-minio mc ls local/kol-platform/silver/
docker exec sme-minio mc ls local/kol-platform/gold/

# Acceptance Criteria:
# - Bronze: ~86K records
# - Silver: ~125K records
# - Gold: ~161K records
```

#### 3.3.3 Data Consistency Tests

| Test ID | Test Name | Description | Priority |
|---------|-----------|-------------|----------|
| DC-001 | Hot-Cold Reconciliation | Compare streaming scores with batch scores | High |
| DC-002 | Kafka-Redis Match | Verify all processed Kafka messages appear in Redis | High |
| DC-003 | Duplicate Detection | Verify no duplicate KOL entries in Silver | Medium |

```bash
# ========================================
# DC-001: Hot-Cold Reconciliation
# ========================================
# This test compares real-time trending scores with batch-computed scores

# Step 1: Get trending score from Redis (Hot Path)
HOT_SCORE=$(docker exec kol-redis redis-cli HGET "trending:tiktok:meoantrongsuong" "trending_score")
echo "Hot Path Score: $HOT_SCORE"

# Step 2: Query Gold layer for comparison (via Trino if available)
# Alternatively, use batch script to compute

# Acceptance Criteria:
# - Scores should be within 10% tolerance
# - Labels should match in 90%+ cases
```

---

### 3.4 Phase 3: ML Inference Testing

#### 3.4.1 Test Cases

| Test ID | Test Name | Description | Priority |
|---------|-----------|-------------|----------|
| ML-001 | API Health Check | Verify /healthz returns ok | Critical |
| ML-002 | Trust Score Prediction | POST /predict/trust with valid input | Critical |
| ML-003 | Success Score Prediction | POST /predict/success with valid input | Critical |
| ML-004 | Trending Score Calculation | POST /predict/trending with valid input | Critical |
| ML-005 | Batch Prediction | POST /predict/trust/batch with multiple KOLs | High |
| ML-006 | Model Info Endpoint | GET /predict/trust/model-info | Medium |
| ML-007 | Invalid Input Handling | Verify proper error for invalid data | Medium |
| ML-008 | Latency SLA | Verify < 50ms response time | High |

#### 3.4.2 Test Commands

```bash
# ========================================
# ML-001: API Health Check
# ========================================
curl -X GET http://localhost:8000/healthz

# Expected Response:
# {"ok": true, "version": "1.0.0", "timestamp": "..."}

# Acceptance Criteria:
# - HTTP 200
# - ok = true

# ========================================
# ML-002: Trust Score Prediction
# ========================================
curl -X POST http://localhost:8000/predict/trust \
  -H "Content-Type: application/json" \
  -d '{
    "kol_id": "test_kol_001",
    "followers_count": 100000,
    "following_count": 500,
    "post_count": 150,
    "favorites_count": 500000,
    "account_age_days": 730,
    "verified": true,
    "has_bio": true,
    "has_url": true,
    "has_profile_image": true,
    "bio_length": 150
  }'

# Expected Response:
# {
#   "kol_id": "test_kol_001",
#   "trust_score": 91.44,       # Range: 0-100
#   "is_trustworthy": true,      # true if score >= 50
#   "confidence": 0.89,          # Range: 0-1
#   "risk_level": "low",         # low|moderate|elevated|high
#   "prediction_source": "realtime",
#   "model_version": "local:lgbm_optuna_model.pkl",
#   "timestamp": "2025-12-12T..."
# }

# Acceptance Criteria:
# - HTTP 200
# - trust_score between 0-100
# - Response time < 50ms

# ========================================
# ML-003: Success Score Prediction
# ========================================
curl -X POST http://localhost:8000/predict/success \
  -H "Content-Type: application/json" \
  -d '{
    "kol_id": "test_kol_viral",
    "video_views": 1000000,
    "video_likes": 80000,
    "video_comments": 5000,
    "video_shares": 3000,
    "engagement_total": 88000,
    "engagement_rate": 0.088,
    "est_clicks": 30000,
    "est_ctr": 0.03,
    "price": 199000
  }'

# Expected Response:
# {
#   "kol_id": "test_kol_viral",
#   "success_score": 78.50,      # Range: 0-100
#   "success_label": "High",     # High|Not-High
#   "confidence": 0.85,
#   "method": "ml",              # ml|rule_based
#   "model_version": "v2_binary",
#   "timestamp": "..."
# }

# Acceptance Criteria:
# - HTTP 200
# - success_score between 0-100
# - success_label is "High" or "Not-High"

# ========================================
# ML-004: Trending Score Calculation
# ========================================
curl -X POST http://localhost:8000/predict/trending \
  -H "Content-Type: application/json" \
  -d '{
    "kol_id": "test_kol_viral",
    "current_velocity": 100,
    "baseline_velocity": 20,
    "global_avg_velocity": 30,
    "momentum": 0.8
  }'

# Expected Response:
# {
#   "kol_id": "test_kol_viral",
#   "trending_score": 95.23,     # Range: 0-100
#   "trending_label": "Viral",   # Cold|Normal|Warm|Hot|Viral
#   "personal_growth": 5.0,      # current/baseline
#   "market_position": 3.33,     # current/global_avg
#   "raw_score": 4.86,
#   "model_version": "v2",
#   "timestamp": "..."
# }

# Acceptance Criteria:
# - HTTP 200
# - trending_score between 0-100
# - trending_label is valid
# - personal_growth = 100/20 = 5.0

# ========================================
# ML-005: Batch Prediction
# ========================================
curl -X POST http://localhost:8000/predict/trust/batch \
  -H "Content-Type: application/json" \
  -d '{
    "kols": [
      {
        "kol_id": "kol_001",
        "followers_count": 50000,
        "following_count": 1000,
        "post_count": 200,
        "favorites_count": 100000,
        "account_age_days": 365,
        "verified": false,
        "has_bio": true,
        "has_url": false,
        "has_profile_image": true,
        "bio_length": 50
      },
      {
        "kol_id": "kol_002",
        "followers_count": 500000,
        "following_count": 200,
        "post_count": 500,
        "favorites_count": 2000000,
        "account_age_days": 1000,
        "verified": true,
        "has_bio": true,
        "has_url": true,
        "has_profile_image": true,
        "bio_length": 200
      }
    ]
  }'

# Expected Response:
# {
#   "predictions": [...],
#   "total": 2,
#   "model_version": "local:lgbm_optuna_model.pkl",
#   "processing_time_ms": 25.5
# }

# Acceptance Criteria:
# - HTTP 200
# - predictions.length == 2
# - processing_time_ms < 100ms for 2 KOLs

# ========================================
# ML-006: Model Info
# ========================================
curl -X GET http://localhost:8000/predict/trust/model-info

# Expected Response:
# {
#   "model_name": "trust-score-lightgbm-optuna",
#   "model_stage": "Production",
#   "features_count": 29,
#   "status": "ready"
# }

# ========================================
# ML-007: Invalid Input Handling
# ========================================
curl -X POST http://localhost:8000/predict/trust \
  -H "Content-Type: application/json" \
  -d '{
    "kol_id": "invalid_kol",
    "followers_count": -100
  }'

# Expected Response:
# HTTP 422 Unprocessable Entity
# {
#   "detail": [{"loc": ["body", "followers_count"], ...}]
# }

# ========================================
# ML-008: Latency Measurement
# ========================================
# Using curl with timing

curl -o /dev/null -s -w "Time: %{time_total}s\n" \
  -X POST http://localhost:8000/predict/trust \
  -H "Content-Type: application/json" \
  -d '{"kol_id":"latency_test","followers_count":10000,"following_count":100,"post_count":50,"favorites_count":5000,"account_age_days":100,"verified":false,"has_bio":true,"has_url":false,"has_profile_image":true,"bio_length":20}'

# Acceptance Criteria:
# - Time < 0.050 seconds (50ms)
```

#### 3.4.3 Score Interpretation Verification

| Score Type | Range | Expected Label | Test Value |
|------------|-------|----------------|------------|
| Trust | 80-100 | Highly Trustworthy | followers=1M, verified=true |
| Trust | 60-79 | Moderately Trustworthy | followers=100K, verified=false |
| Trust | 40-59 | Needs Review | followers=5K, high_activity |
| Trust | 0-39 | Likely Untrustworthy | fake patterns |
| Trending | 80-100 | Viral | velocity 5x baseline |
| Trending | 60-79 | Hot | velocity 3x baseline |
| Trending | 40-59 | Warm | velocity 1.5x baseline |
| Success | 50-100 | High | high engagement + CTR |
| Success | 0-49 | Not-High | low engagement |

---

### 3.5 Phase 4: Visualization Testing

#### 3.5.1 Test Cases

| Test ID | Test Name | Description | Priority |
|---------|-----------|-------------|----------|
| VIZ-001 | Dashboard Load | Verify Streamlit dashboard loads | Critical |
| VIZ-002 | Real-time Data | Verify trending KOLs display correctly | High |
| VIZ-003 | API-Dashboard Sync | Verify dashboard matches API response | High |
| VIZ-004 | Auto-refresh | Verify 5s polling interval works | Medium |
| VIZ-005 | Error Handling | Verify graceful error display | Medium |

#### 3.5.2 Test Commands

```bash
# ========================================
# VIZ-001: Dashboard Load
# ========================================
# Access: http://localhost:8501

# Manual checks:
# 1. Page loads within 5 seconds
# 2. "Realtime Hot KOL" page accessible
# 3. No error banners displayed

# Automated check (curl for 200 OK)
curl -o /dev/null -s -w "%{http_code}" http://localhost:8501

# Acceptance Criteria:
# - HTTP 200

# ========================================
# VIZ-002: Real-time Data Verification
# ========================================
# Compare dashboard data with Redis

# Step 1: Get top KOL from Redis
TOP_KOL=$(docker exec kol-redis redis-cli ZREVRANGE "ranking:tiktok:trending" 0 0)
echo "Top KOL in Redis: $TOP_KOL"

# Step 2: Get score from Redis
SCORE=$(docker exec kol-redis redis-cli HGET "trending:tiktok:$TOP_KOL" "trending_score")
echo "Score: $SCORE"

# Step 3: Manually verify this KOL appears at top of dashboard

# ========================================
# VIZ-003: API-Dashboard Sync
# ========================================
# Get trending from API
curl -s http://localhost:8000/api/v1/trending?limit=5 | jq '.data[0]'

# Compare with dashboard display
# - KOL ID should match
# - Score should match (Â±0.1)
# - Label should match
```

---

### 3.6 Automated Test Script

Create a comprehensive test runner that executes all phases:

```bash
#!/bin/bash
# ============================================
# E2E Test Runner for KOL Analytics Platform
# ============================================

set -e

echo "========================================"
echo "  KOL ANALYTICS PLATFORM E2E TEST"
echo "  $(date '+%Y-%m-%d %H:%M:%S')"
echo "========================================"

PASSED=0
FAILED=0
TOTAL=0

# Function to run a test
run_test() {
    local test_id=$1
    local test_name=$2
    local test_cmd=$3
    
    TOTAL=$((TOTAL + 1))
    echo -n "[$test_id] $test_name... "
    
    if eval "$test_cmd" > /dev/null 2>&1; then
        echo "âœ… PASS"
        PASSED=$((PASSED + 1))
    else
        echo "âŒ FAIL"
        FAILED=$((FAILED + 1))
    fi
}

echo ""
echo "ğŸ“‹ PHASE 1: INGESTION VALIDATION"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

run_test "ING-001" "Kafka topics exist" \
    "docker exec kol-redpanda rpk topic list | grep -q 'kol.videos.raw'"

run_test "ING-002" "Videos topic has messages" \
    "docker exec kol-redpanda rpk topic describe kol.videos.raw --print-offsets | grep -q '0:'"

echo ""
echo "ğŸ“‹ PHASE 2: PIPELINE INTEGRITY"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

run_test "HOT-001" "Redis has trending keys" \
    "docker exec kol-redis redis-cli KEYS 'trending:*' | grep -q 'trending'"

run_test "HOT-002" "Redis ranking exists" \
    "docker exec kol-redis redis-cli EXISTS 'ranking:tiktok:trending' | grep -q '1'"

echo ""
echo "ğŸ“‹ PHASE 3: ML INFERENCE"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

run_test "ML-001" "API health check" \
    "curl -sf http://localhost:8000/healthz | grep -q 'ok'"

run_test "ML-002" "Trust prediction endpoint" \
    "curl -sf -X POST http://localhost:8000/predict/trust \
        -H 'Content-Type: application/json' \
        -d '{\"kol_id\":\"test\",\"followers_count\":10000,\"following_count\":100,\"post_count\":50,\"favorites_count\":5000,\"account_age_days\":100,\"verified\":false,\"has_bio\":true,\"has_url\":false,\"has_profile_image\":true,\"bio_length\":20}' \
        | grep -q 'trust_score'"

run_test "ML-003" "Success prediction endpoint" \
    "curl -sf -X POST http://localhost:8000/predict/success \
        -H 'Content-Type: application/json' \
        -d '{\"kol_id\":\"test\",\"video_views\":10000,\"video_likes\":500,\"video_comments\":50,\"video_shares\":20,\"engagement_total\":570,\"engagement_rate\":0.057,\"est_clicks\":100,\"est_ctr\":0.01,\"price\":50000}' \
        | grep -q 'success_score'"

run_test "ML-004" "Trending calculation endpoint" \
    "curl -sf -X POST http://localhost:8000/predict/trending \
        -H 'Content-Type: application/json' \
        -d '{\"kol_id\":\"test\",\"current_velocity\":50,\"baseline_velocity\":10,\"global_avg_velocity\":20,\"momentum\":0.5}' \
        | grep -q 'trending_score'"

echo ""
echo "ğŸ“‹ PHASE 4: VISUALIZATION"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

run_test "VIZ-001" "Dashboard accessible" \
    "curl -sf -o /dev/null http://localhost:8501"

run_test "VIZ-002" "API trending endpoint" \
    "curl -sf http://localhost:8000/api/v1/trending | grep -q 'data'"

echo ""
echo "========================================"
echo "  TEST SUMMARY"
echo "========================================"
echo "  Total:  $TOTAL"
echo "  Passed: $PASSED"
echo "  Failed: $FAILED"
echo "  Rate:   $(echo "scale=1; $PASSED * 100 / $TOTAL" | bc)%"
echo "========================================"

if [ $FAILED -eq 0 ]; then
    echo "âœ… ALL TESTS PASSED"
    exit 0
else
    echo "âŒ SOME TESTS FAILED"
    exit 1
fi
```

---

### 3.7 Performance Benchmarks

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| **API Response Time (p95)** | < 100ms | 45ms | âœ… Excellent |
| **Streaming Latency** | < 60s | 30s | âœ… Good |
| **Model Inference Time** | < 50ms | 12ms | âœ… Excellent |
| **Batch ETL (Bronzeâ†’Silver)** | < 30 min | ~10 min | âœ… Good |
| **Batch ETL (Silverâ†’Gold)** | < 30 min | ~15 min | âœ… Good |
| **Redis Hit Rate** | > 90% | 94.7% | âœ… Excellent |

---

## 4. Next Actions

### 4.1 Immediate Actions (This Sprint)

| Priority | Action | Owner | Status |
|----------|--------|-------|--------|
| ğŸ”´ P0 | Fix SEC-001: Remove hardcoded credentials | DevOps | ğŸ”„ Pending |
| ğŸ”´ P0 | Fix SEC-003: Implement API authentication | Backend | ğŸ”„ Pending |
| ğŸŸ¡ P1 | Run E2E test suite on staging | QA | ğŸ“‹ Planned |
| ğŸŸ¡ P1 | Implement unit tests (TEST-001) | Backend | ğŸ“‹ Planned |
| ğŸŸ¢ P2 | Set up CI/CD pipeline for automated testing | DevOps | ğŸ“‹ Planned |

### 4.2 Short-term Actions (Next 2 Sprints)

| Priority | Action | Owner | Status |
|----------|--------|-------|--------|
| ğŸŸ¡ P1 | Implement Redis connection pooling (PERF-002) | Backend | ğŸ“‹ Planned |
| ğŸŸ¡ P1 | Add structured logging (LOG-001) | Backend | ğŸ“‹ Planned |
| ğŸŸ¢ P2 | Enable Spark dynamic allocation (PERF-001) | Data Eng | ğŸ“‹ Planned |
| ğŸŸ¢ P2 | Extract config magic numbers (CFG-001) | Backend | ğŸ“‹ Planned |

### 4.3 Long-term Roadmap

1. **Q1 2026**: Airflow DAG integration for scheduled testing
2. **Q2 2026**: Prometheus/Grafana monitoring for test metrics
3. **Q3 2026**: Chaos engineering tests (failure injection)
4. **Q4 2026**: Load testing with 10x data volume

---

## Appendix A: Quick Reference Commands

### Infrastructure Check

```bash
# Check all containers
docker ps --format "table {{.Names}}\t{{.Status}}" | grep kol

# Check Spark cluster
curl http://localhost:8080/json/ | jq '.aliveworkers'

# Check Redis health
docker exec kol-redis redis-cli PING

# Check Kafka topics
docker exec kol-redpanda rpk topic list
```

### Data Verification

```bash
# Count Redis keys
docker exec kol-redis redis-cli DBSIZE

# View trending scores
docker exec kol-redis redis-cli ZREVRANGE "ranking:tiktok:trending" 0 9 WITHSCORES

# Check MinIO buckets
docker exec sme-minio mc ls local/kol-platform/
```

### API Testing

```bash
# Health check
curl http://localhost:8000/healthz

# Swagger UI
open http://localhost:8000/docs

# Trending KOLs
curl http://localhost:8000/api/v1/trending?limit=5
```

---

## Appendix B: Troubleshooting Guide

### Issue: Streaming job fails to start

```bash
# Check Spark logs
docker logs kol-spark-master --tail 100

# Verify Kafka connectivity
docker exec kol-spark-master ping kol-redpanda

# Restart Spark cluster
docker restart kol-spark-master kol-spark-worker-1 kol-spark-worker-2
```

### Issue: Redis is empty after streaming

```bash
# Verify Kafka has data
docker exec kol-redpanda rpk topic consume kol.videos.raw --num 1

# Check streaming job is consuming
docker logs kol-spark-master --tail 50 | grep "Batch"

# Verify Redis connectivity from Spark
docker exec kol-spark-master python -c "import redis; print(redis.Redis(host='redis').ping())"
```

### Issue: API returns 503 Service Unavailable

```bash
# Check model files exist
docker exec kol-api ls -la /app/models/artifacts/trust/

# Check MLflow connectivity
docker exec kol-api curl http://kol-mlflow:5000/health

# Restart API
docker restart kol-api
```

---

**Document End**

> **Prepared by**: Principal Data Solutions Architect  
> **Review Status**: Pending Technical Review  
> **Next Review Date**: December 19, 2025
